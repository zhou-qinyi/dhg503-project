{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "imports",
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'requests'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Import necessary libraries\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlxml\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m html\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mre\u001b[39;00m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'requests'"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import requests\n",
        "from lxml import html\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import random\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# For database connection\n",
        "from sqlalchemy import create_engine, text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "user-agents",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define a list of user agents for random selection\n",
        "user_agents = [\n",
        "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36\",\n",
        "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36\",\n",
        "    \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36\",\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "setup-headers",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set up headers with a random User-Agent\n",
        "headers = {\n",
        "    \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7\",\n",
        "    \"Accept-Language\": \"ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7\",\n",
        "    \"Cache-Control\": \"no-cache\",\n",
        "    \"Connection\": \"keep-alive\",\n",
        "    \"Content-Type\": \"application/x-www-form-urlencoded\",\n",
        "    \"Origin\": \"https://sillok.history.go.kr\",\n",
        "    \"Pragma\": \"no-cache\",\n",
        "    \"Referer\": \"https://sillok.history.go.kr/mc/inspectionMonthList.do\",\n",
        "    \"Sec-Fetch-Dest\": \"document\",\n",
        "    \"Sec-Fetch-Mode\": \"navigate\",\n",
        "    \"Sec-Fetch-Site\": \"same-origin\",\n",
        "    \"Sec-Fetch-User\": \"?1\",\n",
        "    \"Upgrade-Insecure-Requests\": \"1\",\n",
        "    \"User-Agent\": random.choice(user_agents),\n",
        "    \"sec-ch-ua\": '\"Google Chrome\";v=\"125\", \"Chromium\";v=\"125\", \"Not.A/Brand\";v=\"24\"',\n",
        "    \"sec-ch-ua-mobile\": \"?0\",\n",
        "    \"sec-ch-ua-platform\": '\"macOS\"',\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "markdown-fetch-month",
      "metadata": {},
      "source": [
        "### Function: fetch_month_ids\n",
        "\n",
        "This function takes a `king_id` as input and sends a POST request to the appropriate URL (depending on the type of `king_id`).\n",
        "\n",
        "It parses the HTML response to extract month IDs and month names using XPath and regular expressions. A random delay is added after the request for safety.\n",
        "\n",
        "**Parameters:**\n",
        "\n",
        "- `king_id`: A string identifier (e.g., `msilok_001` or `qsilok_001`).\n",
        "\n",
        "**Returns:**\n",
        "\n",
        "- A list of tuples, each containing a month ID and its corresponding month name.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "code-fetch-month",
      "metadata": {},
      "outputs": [],
      "source": [
        "def fetch_month_ids(king_id):\n",
        "    # Prepare form data for the POST request\n",
        "    data = {\"id\": king_id}\n",
        "\n",
        "    # Choose URL based on king_id type\n",
        "    url = (\n",
        "        \"https://sillok.history.go.kr/mc/inspectionMonthList.do\"\n",
        "        if king_id[0] == \"m\"\n",
        "        else \"https://sillok.history.go.kr/mc/inspectionMonthList.do?treeType=C\"\n",
        "    )\n",
        "\n",
        "    # Send POST request\n",
        "    response = requests.post(url, headers=headers, data=data)\n",
        "\n",
        "    # Safety pause to avoid overwhelming the server\n",
        "    time.sleep(random.uniform(1, 3))\n",
        "\n",
        "    # Parse HTML response\n",
        "    text = response.text\n",
        "    month_url = html.fromstring(text).xpath(\n",
        "        '//*[@id=\"cont_area\"]/div/div[2]/ul[2]/li/ul/li/a/@href'\n",
        "    )\n",
        "\n",
        "    # Extract month IDs and names using regular expressions\n",
        "    month_id = [re.search(r\"([m,q]silok_.*?)'\", month).group(1) for month in month_url]\n",
        "    month_name = [re.search(r\"(\\d{4}년 .*월?)'\", month).group(1) for month in month_url]\n",
        "\n",
        "    return list(zip(month_id, month_name))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "markdown-fetch-day",
      "metadata": {},
      "source": [
        "### Function: fetch_day_ids\n",
        "\n",
        "This function accepts a tuple containing a month ID and its name, and sends a POST request to fetch day IDs and associated date information.\n",
        "\n",
        "It parses the HTML response using XPath and regular expressions, and returns a list of tuples with day IDs and date info. A safety pause is included after the request.\n",
        "\n",
        "**Parameters:**\n",
        "\n",
        "- `month_id`: A tuple (`month_id`, `month_name`).\n",
        "\n",
        "**Returns:**\n",
        "\n",
        "- A list of tuples, each containing a day ID and the corresponding date information.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "code-fetch-day",
      "metadata": {},
      "outputs": [],
      "source": [
        "def fetch_day_ids(month_id):\n",
        "    data = {\"id\": month_id[0], \"dateInfo\": month_id[1]}\n",
        "    url = (\n",
        "        \"https://sillok.history.go.kr/mc/inspectionDayList.do?treeType=M\"\n",
        "        if month_id[0][0] == \"m\"\n",
        "        else \"https://sillok.history.go.kr/mc/inspectionDayList.do?treeType=C\"\n",
        "    )\n",
        "    response = requests.post(url, headers=headers, data=data)\n",
        "\n",
        "    time.sleep(random.uniform(1, 3))\n",
        "\n",
        "    text = response.text\n",
        "    days = html.fromstring(text).xpath(\n",
        "        '//*[@id=\"cont_area\"]/div/div[1]/div/span[2]/ul/li/a/@href'\n",
        "    )\n",
        "\n",
        "    day_ids = [re.search(r\"([m,q]silok_.*?)'\", day).group(1) for day in days]\n",
        "    date_info = [re.findall(r\"'([^']*)'\", day)[-1] for day in days]\n",
        "    return list(zip(day_ids, date_info))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "markdown-fetch-article",
      "metadata": {},
      "source": [
        "### Function: fetch_article_ids\n",
        "\n",
        "This function takes a tuple with a day ID and its associated date information and sends a POST request to obtain article IDs for that day.\n",
        "\n",
        "It parses the HTML response using XPath to extract the article identifiers. A random delay is added after the request.\n",
        "\n",
        "**Parameters:**\n",
        "\n",
        "- `day_id`: A tuple (`day_id`, `date_info`).\n",
        "\n",
        "**Returns:**\n",
        "\n",
        "- A list of article IDs as strings.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "code-fetch-article",
      "metadata": {},
      "outputs": [],
      "source": [
        "def fetch_article_ids(day_id):\n",
        "    data = {\"id\": day_id[0], \"dateInfo\": day_id[1]}\n",
        "    response = requests.post(\n",
        "        \"https://sillok.history.go.kr/mc/inspectionDayList.do\",\n",
        "        headers=headers,\n",
        "        data=data,\n",
        "    )\n",
        "\n",
        "    time.sleep(random.uniform(1, 3))\n",
        "\n",
        "    text = response.text\n",
        "    articles = html.fromstring(text).xpath(\n",
        "        \"//*[@id='cont_area']/div/div[3]/div/div[1]/ul/li/a/@id\"\n",
        "    )\n",
        "    articles = [str(a) for a in articles]\n",
        "    return articles"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "markdown-process-king",
      "metadata": {},
      "source": [
        "### Function: process_king_ids\n",
        "\n",
        "This function orchestrates the entire scraping process:\n",
        "\n",
        "1. It creates a list of king IDs (both `msilok` and `qsilok` types).\n",
        "2. Iterates over these IDs to fetch month IDs, then day IDs, and finally article IDs.\n",
        "3. Aggregates all article IDs into a single list.\n",
        "\n",
        "**Returns:**\n",
        "\n",
        "- A list of article IDs collected from the website.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "code-process-king",
      "metadata": {},
      "outputs": [],
      "source": [
        "def process_king_ids():\n",
        "    month_ids = []\n",
        "    day_ids = []\n",
        "    article_ids = []\n",
        "\n",
        "    # Generate king IDs for both types\n",
        "    mking_ids = [f\"msilok_{i:03d}\" for i in range(1, 16)]\n",
        "    qking_ids = [f\"qsilok_{i:03d}\" for i in range(1, 14)]\n",
        "    king_ids = mking_ids + qking_ids\n",
        "\n",
        "    # Fetch month IDs for each king\n",
        "    for king_id in tqdm(\n",
        "        king_ids, desc=\"Fetching month IDs from each king\", total=len(king_ids)\n",
        "    ):\n",
        "        try:\n",
        "            months = fetch_month_ids(king_id)\n",
        "            month_ids.extend(months)\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to fetch month IDs for {king_id}: {e}\")\n",
        "            continue\n",
        "\n",
        "    print(f\"Total {len(month_ids)} months fetched\")\n",
        "\n",
        "    # Fetch day IDs for each month (limit to first 100 for demonstration)\n",
        "    for month in tqdm(\n",
        "        month_ids[:100],\n",
        "        desc=\"Fetching day IDs from each month\",\n",
        "        total=len(month_ids[:100]),\n",
        "    ):\n",
        "        try:\n",
        "            days = fetch_day_ids(month)\n",
        "            day_ids.extend(days)\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to fetch day IDs for {month}: {e}\")\n",
        "            continue\n",
        "\n",
        "    # Fetch article IDs for each day\n",
        "    for day in tqdm(\n",
        "        day_ids, desc=\"Fetching article IDs from each day\", total=len(day_ids)\n",
        "    ):\n",
        "        try:\n",
        "            articles = fetch_article_ids(day)\n",
        "            article_ids.extend(articles)\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to fetch article IDs for {day}: {e}\")\n",
        "            continue\n",
        "\n",
        "    return article_ids"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "markdown-execute-scrape",
      "metadata": {},
      "source": [
        "### Execute the Scraping Process\n",
        "\n",
        "Call the `process_king_ids` function to start the scraping process. The returned list of article IDs will be used for downloading individual article pages.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "execute-scrape",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Execute the scraping process and collect article IDs\n",
        "article_ids = process_king_ids()\n",
        "print(f\"Total {len(article_ids)} article IDs fetched\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "markdown-download-html",
      "metadata": {},
      "source": [
        "### Download HTML Pages\n",
        "\n",
        "This block downloads the HTML content of each article page and saves it to the `data/mqsillok/raw/html` directory. A safety pause is added between requests.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "download-html",
      "metadata": {},
      "outputs": [],
      "source": [
        "save_dir = \"data/mqsillok/raw/html\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "for article_id in tqdm(\n",
        "    article_ids, desc=\"Downloading HTML pages\", total=len(article_ids)\n",
        "):\n",
        "    try:\n",
        "        url = f\"https://sillok.history.go.kr/mc/id/{article_id}\"\n",
        "        response = requests.get(url, headers=headers)\n",
        "\n",
        "        # Safety pause\n",
        "        time.sleep(random.uniform(1, 3))\n",
        "        html_content = response.text\n",
        "\n",
        "        # Save HTML content to a file\n",
        "        with open(\n",
        "            os.path.join(save_dir, f\"{article_id}.html\"), \"w\", encoding=\"utf-8\"\n",
        "        ) as f:\n",
        "            f.write(html_content)\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to download HTML for {article_id}: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "markdown-extract-data",
      "metadata": {},
      "source": [
        "### Extract Data from HTML Pages\n",
        "\n",
        "This block reads the saved HTML files, extracts information (title, year, date, content, and king) from each page using XPath, and compiles the data into a pandas DataFrame.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "extract-data",
      "metadata": {},
      "outputs": [],
      "source": [
        "data = []\n",
        "for article_id in tqdm(\n",
        "    article_ids, desc=\"Extracting data from HTML pages\", total=len(article_ids)\n",
        "):\n",
        "    try:\n",
        "        file_path = os.path.join(save_dir, f\"{article_id}.html\")\n",
        "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "            html_content = f.read()\n",
        "\n",
        "        page = html.fromstring(html_content)\n",
        "\n",
        "        # Extract title\n",
        "        title = page.xpath(\n",
        "            \"/html/body/div[2]/div[2]/div[2]/div/div[1]/div/span/text()\"\n",
        "        )[0].strip()\n",
        "\n",
        "        # Extract year (remove the '년' character)\n",
        "        year_text = page.xpath(\n",
        "            \"/html/body/div[2]/div[2]/div[2]/div/div[1]/div/span/span/text()\"\n",
        "        )[0].strip()\n",
        "        year = int(year_text.replace(\"년\", \"\"))\n",
        "\n",
        "        # Extract content text\n",
        "        content = \" \".join(\n",
        "            p.text_content().strip()\n",
        "            for p in page.xpath(\"/html/body/div[2]/div[2]/div[2]/div/div[3]/div/div//p\")\n",
        "        )\n",
        "\n",
        "        # Extract date\n",
        "        date = page.xpath(\"/html/body/div[2]/div[2]/div[2]/div/ul[1]/li[6]/a/text()\")[\n",
        "            0\n",
        "        ].strip()\n",
        "\n",
        "        # Extract king information from the URL and clean it up\n",
        "        king_raw = page.xpath(\n",
        "            \"/html/body/div[2]/div[2]/div[2]/div/ul[1]/li[3]/a/@href\"\n",
        "        )[0].strip()\n",
        "        king = king_raw.split(\", \")[3].strip(\";\").strip(\"')\").replace(\"實錄\", \"\")\n",
        "\n",
        "        info = {\n",
        "            \"title\": title,\n",
        "            \"year\": year,\n",
        "            \"date\": date,\n",
        "            \"content\": content,\n",
        "            \"king\": king,\n",
        "        }\n",
        "        data.append(info)\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to extract data for {article_id}: {e}\")\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "print(f\"Extracted data for {len(df)} articles\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bcd22d0e",
      "metadata": {},
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "markdown-save-db",
      "metadata": {},
      "source": [
        "### Save Data to PostgreSQL Database\n",
        "\n",
        "This block creates a PostgreSQL table (dropping it if it exists) and inserts the data from the DataFrame into the table using SQLAlchemy. Make sure to update the connection string with your credentials.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "save-to-db",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the PostgreSQL connection string (update with your credentials)\n",
        "db_connection_str = \"postgresql://dhg503:dhg503dhg503@localhost:54503/dhg503\"\n",
        "engine = create_engine(db_connection_str)\n",
        "\n",
        "# SQL to drop the table if it exists and create a new table\n",
        "create_table_sql = \"\"\"\n",
        "DROP TABLE IF EXISTS mqshillu;\n",
        "CREATE TABLE mqshillu (\n",
        "    title TEXT,\n",
        "    year INTEGER,\n",
        "    date TEXT,\n",
        "    content TEXT,\n",
        "    king TEXT\n",
        ");\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54e28b93",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Execute SQL statements within a transaction\n",
        "with engine.connect() as conn:\n",
        "    conn.execute(text(\"BEGIN\"))\n",
        "    conn.execute(text(create_table_sql))\n",
        "\n",
        "    # Insert data row by row from the DataFrame\n",
        "    for _, row in df.iterrows():\n",
        "        insert_sql = text(\n",
        "            \"\"\"\n",
        "            INSERT INTO mqshillu (title, year, date, content, king)\n",
        "            VALUES (:title, :year, :date, :content, :king)\n",
        "            \"\"\"\n",
        "        )\n",
        "        conn.execute(\n",
        "            insert_sql,\n",
        "            {\n",
        "                \"title\": row[\"title\"],\n",
        "                \"year\": row[\"year\"],\n",
        "                \"date\": row[\"date\"],\n",
        "                \"content\": row[\"content\"],\n",
        "                \"king\": row[\"king\"],\n",
        "            },\n",
        "        )\n",
        "\n",
        "    conn.execute(text(\"COMMIT\"))\n",
        "\n",
        "print(\"Data successfully saved to the PostgreSQL database.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "499d5c88",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
<<<<<<< Updated upstream
      "version": "3.11.10"
=======
      "version": "3.12.9"
>>>>>>> Stashed changes
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
